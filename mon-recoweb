#!/usr/bin/env bash
# mon-recoweb (mini) — annonces vertes, whatweb d'abord, filtres ON, per-extension, résultats en évidence
# ---------------------------------------------------------------------------------------------------
# Utilisation : mon-recoweb <IP|HOST|URL> [-x php,html,txt] [--no-filters] [-w <wordlist>] [-T <threads>] [-p <rate>] [--http|--https]
# Conserve uniquement : mon-recoweb_<target>/{whatweb.txt, summary_dirs.txt, summary_files.txt}
# Dépendances : whatweb, ffuf, curl, awk, sed
# ---------------------------------------------------------------------------------------------------
# SIG: mon-recoweb vMini-perext-whatweb-2025-09-05-g

set -euo pipefail

# Couleurs (désactivées si pas TTY)
if [[ -t 1 ]]; then
  C_B=$'\e[1m'; C_G=$'\e[32m'; C_Y=$'\e[33m'; C_R=$'\e[31m'; C_C=$'\e[36m'; C_RST=$'\e[0m'
  C_HI="${C_B}${C_C}"     # surlignage (cyan gras) pour les résultats
else
  C_B=''; C_G=''; C_Y=''; C_R=''; C_C=''; C_RST=''; C_HI=''
fi

ok()   { echo -e "${C_G}[✓]${C_RST} $*"; }
warn() { echo -e "${C_Y}[!]${C_RST} $*"; }
err()  { echo -e "${C_R}[x]${C_RST} $*" >&2; }

usage() {
  cat <<'EOF'
mon-recoweb <IP|HOST|URL> [options]

Options :
  -x "php,html,txt"   Extensions à tester pour la phase FICHIERS (défaut: php,html,txt)
  -w <wordlist>      Wordlist pour FUZZ (défaut: /usr/share/seclists/Discovery/Web-Content/common.txt)
  -T <threads>       Threads ffuf (défaut: 40)
  -p <rate>          Rate limit ffuf (ex: 100/sec)
  --no-filters       Désactive -fs auto + -fc 404
  --http             Force http://
  --https            Force https://

Comportement :
- Annonce les 3 phases : WhatWeb, ffuf répertoires, ffuf extensions
- Affiche seulement les résultats (pas la commande ffuf)
- Sauvegarde : whatweb.txt, summary_dirs.txt, summary_files.txt (résumés lisibles)
- Filtre par défaut les contenus 404 et la taille dominante (anti-bruit) pour directories/files

EOF
}

# Défauts
EXTS="php,html,txt"
WORDLIST="/usr/share/seclists/Discovery/Web-Content/common.txt"
THREADS="40"
RATE=""
NO_FILTERS=0
FORCE_SCHEME=""   # "http" | "https" | ""

# Détermination schéma/host
norm_target() {
  local t="$1"
  if [[ "$t" =~ ^https?:// ]]; then
    echo "$t"
  else
    echo "http://$t"
  fi
}

base_url_from() {
  local t="$1"
  # enlève trailing slash
  t="${t%/}"
  echo "$t"
}

host_from_url() {
  # extrait l'host d'une URL http(s)://host[:port]
  awk -F[/:] '{print $4}' <<< "$1"
}

# Auto-détection taille "bruit" via une petite passe (pour -fs)
detect_noise_size() {
  local url="$1"
  local size
  size=$(curl -sk -o /dev/null -w '%{size_download}' "$url" || echo "")
  # retourne vide si pas exploitable
  [[ -n "$size" && "$size" -gt 0 ]] && echo "$size" || echo ""
}

# Convertit CSV ffuf -> résumé lisible "CODE  len=XXXX    URL"
summarize_csv() {
  local csv="$1" out="$2" status_keep="$3"
  : > "$out"
  # Attend en-tête ffuf standard : "status,length,words,lines,..." puis URL
  awk -F',' -v keep="$status_keep" '
    BEGIN {
      split(keep, karr, " ");
      for (i in karr) wanted[karr[i]] = 1;
    }
    NR==1 {
      # repérer colonnes par nom/position
      for (i=1; i<=NF; i++) {
        h[$i] = i
      }
      s = (h["status"] ? h["status"] : 1)
      l = (h["length"] ? h["length"] : (h["size"] ? h["size"] : 2))
      # Dernière colonne souvent URL
      u = NF
      next
    }
    {
      code=$s; len=$l; url=$u
      gsub(/^"|"$/, "", code); gsub(/^"|"$/, "", len); gsub(/^"|"$/, "", url);
      # Filtre par code si demandé
      if (length(wanted)>0 && wanted[code] != 1) next
      printf "%s  len=%s    %s\n", code, len, url
    }
  ' "$csv" >> "$out"
}

# Options affichables pour ffuf
_ffuf_common_flags() {
  local arr=()
  arr+=( -of csv )
  [[ -n "$RATE" ]] && arr+=( -rate "$RATE" )
  arr+=( -t "$THREADS" )
  echo "${arr[@]}"
}

# Parse --http/--https/--no-filters d'abord si passé avant la cible
tmp_argv=()
while [[ $# -gt 0 ]]; do
  case "${1:-}" in
    --http|--https|--no-filters) tmp_argv+=("$1"); shift ;;
    *) break ;;
  esac
done

# Parse positional TARGET + options
[[ $# -eq 0 ]] && { usage; exit 1; }
if [[ "${1:-}" != -* ]]; then TARGET="$1"; shift; fi
while [[ $# -gt 0 ]]; do
  case "$1" in
    -x) EXTS="$2"; shift 2 ;;
    -w) WORDLIST="$2"; shift 2 ;;
    -T) THREADS="$2"; shift 2 ;;
    -p) RATE="$2"; shift 2 ;;
    --http)  FORCE_SCHEME="http";  shift ;;
    --https) FORCE_SCHEME="https"; shift ;;
    --no-filters) NO_FILTERS=1; shift ;;
    -h|--help) usage; exit 0 ;;
    *) warn "Option inconnue: $1"; shift ;;
  esac
done

# Réinjecter les flags initiaux si besoin
for f in "${tmp_argv[@]}"; do
  case "$f" in
    --http) FORCE_SCHEME="http" ;;
    --https) FORCE_SCHEME="https" ;;
    --no-filters) NO_FILTERS=1 ;;
  esac
done

# Normalisation URL + base
TARGET_URL="$(norm_target "$TARGET")"
[[ -n "$FORCE_SCHEME" ]] && TARGET_URL="$(echo "$TARGET_URL" | sed -E "s#^https?://#${FORCE_SCHEME}://#")"
BASE_URL="$(base_url_from "$TARGET_URL")"
HOST="$(host_from_url "$BASE_URL")"
OUTDIR="mon-recoweb_${HOST}"
mkdir -p "$OUTDIR"

ok "Dossier : ${OUTDIR}"
ok "Base URL : ${BASE_URL}"

# Détection taille bruit (pour -fs) uniquement si filtres actifs
FS_SIZE=""
if [[ "$NO_FILTERS" -eq 0 ]]; then
  FS_SIZE="$(detect_noise_size "${BASE_URL}/definitely-not-exist-$(date +%s).txt" || true)"
fi

# Phase WHATWEB
echo -e "${C_G}Lancement de WhatWeb...${C_RST}"
: > "${OUTDIR}/whatweb.txt"
whatweb --no-errors --log-brief="${OUTDIR}/whatweb.txt" "${BASE_URL}" >/dev/null 2>&1 || true
echo -e "${C_HI}=== WHATWEB ===${C_RST}"
if [[ -s "${OUTDIR}/whatweb.txt" ]]; then
  cat "${OUTDIR}/whatweb.txt"
else
  echo -e "${C_HI}(aucun)${C_RST}"
fi
echo

# Construire les filtres (dirs/files)
STATUS_FILTER=""
if [[ "$NO_FILTERS" -eq 0 ]]; then
  # Toujours ignorer 404
  STATUS_FILTER="-fc 404"
fi

DIR_FILTER=""
FILE_FILTER=""
if [[ "$NO_FILTERS" -eq 0 ]]; then
  # -fs sur taille "bruit" si détectée
  if [[ -n "${FS_SIZE}" ]]; then
    DIR_FILTER="-fs ${FS_SIZE}"
    FILE_FILTER="-fs ${FS_SIZE}"
  fi
fi

# Codes à afficher (résumés) : on retient typiquement 200,204,301,302,307,401,403
SUMMARY_CODES="200 204 301 302 307 401 403"

# Résumés : fabrication
summarize_dirs() { summarize_csv "$1" "$2" "$SUMMARY_CODES"; }
summarize_files() { summarize_csv "$1" "$2" "$SUMMARY_CODES"; }

# ---- 0) Préparer CSV temporaires
CSV_FILES_ALL="$(mktemp "${OUTDIR}/.files_XXXXXX.csv")"

# ---- 1) Répertoires → annonce verte → temp → summary_dirs.txt → afficher résultats
CSV_DIRS="$(mktemp "${OUTDIR}/.dirs_XXXXXX.csv")"
echo -e "${C_G}Lancement de ffuf répertoires...${C_RST}"
ffuf -u "${BASE_URL}/FUZZ" -w "${WORDLIST}" $(_ffuf_common_flags) -o "${CSV_DIRS}" ${DIR_FILTER} >/dev/null 2>&1 || true
summarize_csv "${CSV_DIRS}" "${OUTDIR}/summary_dirs.txt" "${SUMMARY_CODES}"
echo -e "${C_HI}=== RÉPERTOIRES TROUVÉS ===${C_RST}"
if [[ -s "${OUTDIR}/summary_dirs.txt" ]]; then
  while IFS= read -r line; do echo -e "${C_HI}${line}${C_RST}"; done < "${OUTDIR}/summary_dirs.txt"
else
  echo -e "${C_HI}(aucun)${C_RST}"
fi
echo

# ---- 2) Fichiers par extensions → une passe par extension
echo -e "${C_G}Lancement de ffuf extensions...${C_RST}"
IFS=',' read -r -a _ext_arr <<< "$EXTS"
for ext in "${_ext_arr[@]}"; do
  ext="${ext//[[:space:]]/}"   # trim
  [[ -z "$ext" ]] && continue
  CSV_THIS_EXT="$(mktemp "${OUTDIR}/.files_${ext}_XXXXXX.csv")"
  # On reste discret : pas d’affichage commande, uniquement résultats
  ffuf -u "${BASE_URL}/FUZZ" -w "${WORDLIST}" -e "${ext}" $(_ffuf_common_flags) -o "${CSV_THIS_EXT}" ${FILE_FILTER} >/dev/null 2>&1 || true
  # Concaténer en un CSV global
  if [[ -s "$CSV_THIS_EXT" ]]; then
    # On recopie en écrasant l’en-tête sauf pour la première fois
    if [[ ! -s "$CSV_FILES_ALL" ]]; then
      cat "$CSV_THIS_EXT" > "$CSV_FILES_ALL"
    else
      tail -n +2 "$CSV_THIS_EXT" >> "$CSV_FILES_ALL"
    fi
  fi
done

# Résumé fichiers
summarize_csv "${CSV_FILES_ALL}" "${OUTDIR}/summary_files.txt" "${SUMMARY_CODES}"
# Affichage fichiers
echo -e "${C_HI}=== FICHIERS TROUVÉS (ext: ${EXTS}) ===${C_RST}"
if [[ -s "${OUTDIR}/summary_files.txt" ]]; then
  while IFS= read -r line; do echo -e "${C_HI}${line}${C_RST}"; done < "${OUTDIR}/summary_files.txt"
else
  echo -e "${C_HI}(aucun)${C_RST}"
fi

# ---- Nettoyage des temporaires
rm -f "${CSV_DIRS}" "${CSV_FILES_ALL}"

echo
ok "Terminé."
echo "  -> ${OUTDIR}/whatweb.txt"
echo "  -> ${OUTDIR}/summary_dirs.txt"
echo "  -> ${OUTDIR}/summary_files.txt"
