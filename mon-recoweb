#!/usr/bin/env bash
# mon-recoweb (lite, 2 filtres -fs séparés : dirs & files)
# -----------------------------------------------------------------------------------------
# 1) Détection CMS/technos : whatweb
# 2) FFUF (répertoires)  : filtre taille appris sur .../RANDOM_DIR/
# 3) FFUF (fichiers)     : filtre taille appris sur .../RANDOM_FILE.php
# -mc all -k, threads réglables, rate optionnel
# Résultats dans ./mon-recoweb_<target>/ + affichage clair
# Dépendances : whatweb, ffuf, curl, awk, sed
# -----------------------------------------------------------------------------------------

set -euo pipefail

# Couleurs (coupées si pas TTY)
if [[ -t 1 ]]; then
  C_RST=$'\e[0m'; C_B=$'\e[1m'; C_G=$'\e[32m'; C_Y=$'\e[33m'; C_C=$'\e[36m'; C_R=$'\e[31m'
else
  C_RST=''; C_B=''; C_G=''; C_Y=''; C_C=''; C_R=''
fi

TARGET=""
WORDLIST="/usr/share/wordlists/dirb/common.txt"
EXTS="php,txt,html"
THREADS=40
RATE=""
OUTDIR=""
VERBOSE=false
NOFILTER=false
FORCE_HTTP=false
FORCE_HTTPS=false

usage() {
cat <<EOF
${C_B}Usage:${C_RST} mon-recoweb -t <IP|HOST|URL> [options]

  -t <target>     IP/host ou URL (avec/sans schéma)
  -w <wordlist>   Wordlist (def: ${WORDLIST})
  -x <exts>       Extensions fichiers (def: ${EXTS})
  -T <threads>    Threads ffuf (def: ${THREADS})
  -p <rate>       Tempo ffuf, ex: 50ms (facultatif)
  -o <outdir>     Dossier de sortie (def: auto, sans timestamp)
  -v              Verbose
  --http          Forcer HTTP
  --https         Forcer HTTPS
  --no-filter     Désactive les filtres auto (-fs)

Exemples:
  mon-recoweb -t site.htb
  mon-recoweb -t site.htb -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt
  mon-recoweb -t https://site.htb -x php,txt
EOF
}

log() { echo -e "${C_C}[i]${C_RST} $*"; }
ok()  { echo -e "${C_G}[✓]${C_RST} $*"; }
warn(){ echo -e "${C_Y}[!]${C_RST} $*"; }
err() { echo -e "${C_R}[✗]${C_RST} $*" >&2; }

# Parse args
while [[ $# -gt 0 ]]; do
  case "$1" in
    -t) TARGET="$2"; shift 2 ;;
    -w) WORDLIST="$2"; shift 2 ;;
    -x) EXTS="$2"; shift 2 ;;
    -T) THREADS="$2"; shift 2 ;;
    -p) RATE="$2"; shift 2 ;;
    -o) OUTDIR="$2"; shift 2 ;;
    -v) VERBOSE=true; shift ;;
    --http)  FORCE_HTTP=true; shift ;;
    --https) FORCE_HTTPS=true; shift ;;
    --no-filter) NOFILTER=true; shift ;;
    -h|--help) usage; exit 0 ;;
    *) err "Option inconnue: $1"; usage; exit 1 ;;
  esac
done

[[ -z "${TARGET}" ]] && { err "Cible manquante (-t)."; usage; exit 1; }
[[ ! -f "${WORDLIST}" ]] && { err "Wordlist introuvable: ${WORDLIST}"; exit 1; }
command -v whatweb >/dev/null 2>&1 || { err "whatweb manquant"; exit 1; }
command -v ffuf    >/dev/null 2>&1 || { err "ffuf manquant"; exit 1; }

# ---------- Dossier sortie (sans timestamp) ----------
SAFE_TGT="$(echo "${TARGET}" | sed 's#[/:]#_#g')"
OUTDIR="${OUTDIR:-mon-recoweb_${SAFE_TGT}}"
mkdir -p "${OUTDIR}"
ok "Dossier de travail: ${OUTDIR}"

# ---------- Détermination schéma ----------
base_host="${TARGET}"
if [[ "${TARGET}" =~ ^https?:// ]]; then
  BASE_URL="${TARGET%/}"
  base_host="$(echo "${TARGET}" | sed -E 's#^https?://##' | cut -d/ -f1)"
else
  if ${FORCE_HTTP}; then
    BASE_URL="http://${TARGET}"
  elif ${FORCE_HTTPS}; then
    BASE_URL="https://${TARGET}"
  else
    if curl -k -sI "https://${TARGET}" >/dev/null 2>&1; then
      BASE_URL="https://${TARGET}"
    else
      BASE_URL="http://${TARGET}"
    fi
  fi
fi
ok "Base URL : ${BASE_URL}"

# ---------- 1) WHATWEB ----------
log "WhatWeb (-a 3)…"
whatweb -a 3 "${BASE_URL}" | sed -r 's/\x1B\[[0-9;]*[A-Za-z]//g' | tee "${OUTDIR}/whatweb.txt"
whatweb -a 3 "${BASE_URL}" --log-json="${OUTDIR}/whatweb.json" >/dev/null 2>&1 || true
[[ ! -s "${OUTDIR}/whatweb.txt" ]] && warn "whatweb.txt est vide"

# ---------- 2 filtres séparés (taille 404) ----------
DIR_FILTER=""
FILE_FILTER=""

if ! ${NOFILTER}; then
  # Sonde type "répertoire"
  RANDDIR="__dir__$(tr -dc 'a-z0-9' </dev/urandom | head -c 10)/"
  URL_DIR="${BASE_URL}/${RANDDIR}"
  SIZE_DIR="$(curl -k -s -o /dev/null -w '%{size_download}\n' "${URL_DIR}" || echo "0")"

  # Sonde type "fichier" (php par défaut)
  RANDFILE="__file__$(tr -dc 'a-z0-9' </dev/urandom | head -c 10).php"
  URL_FILE="${BASE_URL}/${RANDFILE}"
  SIZE_FILE="$(curl -k -s -o /dev/null -w '%{size_download}\n' "${URL_FILE}" || echo "0")"

  [[ "${SIZE_DIR}"  != "0" ]] && DIR_FILTER="-fs ${SIZE_DIR}"
  [[ "${SIZE_FILE}" != "0" ]] && FILE_FILTER="-fs ${SIZE_FILE}"

  log "Taille 'bruit' DIR  : ${SIZE_DIR}  (URL test: ${URL_DIR})"
  log "Taille 'bruit' FILE : ${SIZE_FILE} (URL test: ${URL_FILE})"
else
  warn "Filtres auto désactivés (--no-filter)"
fi

# ---------- Helpers ----------
run_ffuf () {
  local mode="$1" out_csv="$2" exts_param="$3" size_filter="$4"
  local opts=( -u "${BASE_URL}/FUZZ" -w "${WORDLIST}" -mc all -k -t "${THREADS}" -of csv -o "${out_csv}" )
  [[ -n "${RATE}" ]] && opts+=( -p "${RATE}" )
  [[ -n "${size_filter}" ]] && opts+=( ${size_filter} )
  [[ -n "${exts_param}" ]] && opts+=( -x "${exts_param}" )
  ${VERBOSE} && echo "+ ffuf ${opts[*]}"
  ffuf "${opts[@]}" | sed -n '1,3p' || true
}

summarize_csv () {
  local csv="$1" summary="$2"
  if [[ -s "${csv}" ]]; then
    awk -F',' 'NR==1 {next} {printf "%-4s  len=%-7s  %s\n", $4, $5, $2}' "${csv}" \
      | sed 's|"||g' | sort -u > "${summary}"
  else
    : > "${summary}"
  fi
}

# ---------- 2) FFUF — RÉPERTOIRES (sans extensions, filtre DIR) ----------
log "FFUF (répertoires) : wordlist=${WORDLIST} | threads=${THREADS} ${RATE:+| rate=${RATE}} ${DIR_FILTER:+| ${DIR_FILTER}}"
CSV_DIRS="${OUTDIR}/ffuf_dirs.csv"
SUMMARY_DIRS="${OUTDIR}/summary_dirs.txt"
run_ffuf "dirs" "${CSV_DIRS}" "" "${DIR_FILTER}"
summarize_csv "${CSV_DIRS}" "${SUMMARY_DIRS}"

# ---------- 3) FFUF — FICHIERS (avec extensions, filtre FILE) ----------
log "FFUF (fichiers: ${EXTS}) : wordlist=${WORDLIST} | threads=${THREADS} ${RATE:+| rate=${RATE}} ${FILE_FILTER:+| ${FILE_FILTER}}"
CSV_FILES="${OUTDIR}/ffuf_files.csv"
SUMMARY_FILES="${OUTDIR}/summary_files.txt"
run_ffuf "files" "${CSV_FILES}" "${EXTS}" "${FILE_FILTER}"
summarize_csv "${CSV_FILES}" "${SUMMARY_FILES}"

# ---------- Affichage clair ----------
echo
echo -e "${C_B}=== RÉPERTOIRES TROUVÉS (scan sans extensions) ===${C_RST}"
if [[ -s "${SUMMARY_DIRS}" ]]; then
  grep -E '^(301|302|401|403|200|500)' "${SUMMARY_DIRS}" || true
  grep -Ev '^(301|302|401|403|200|500)' "${SUMMARY_DIRS}" || true
else
  echo "(aucun résultat)"
fi

echo
echo -e "${C_B}=== FICHIERS TROUVÉS (scan avec extensions: ${EXTS}) ===${C_RST}"
if [[ -s "${SUMMARY_FILES}" ]]; then
  grep -E '^(301|302|401|403|200|500)' "${SUMMARY_FILES}" || true
  grep -Ev '^(301|302|401|403|200|500)' "${SUMMARY_FILES}" || true
else
  echo "(aucun résultat)"
fi

echo
ok "Recon web (lite, 2 filtres) terminé."
echo -e "  → Dossier : ${C_B}${OUTDIR}${C_RST}"
echo "    - whatweb.txt | whatweb.json"
echo "    - ffuf_dirs.csv | summary_dirs.txt"
echo "    - ffuf_files.csv | summary_files.txt"
