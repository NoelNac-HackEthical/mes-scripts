#!/usr/bin/env bash
# mon-recoweb (version simplifiée, sans timestamp dans les résultats)
# ------------------------------------------------------------
# 1) Détection CMS/technos : whatweb
# 2) Énumération répertoires/fichiers : ffuf
#    - wordlist par défaut : /usr/share/wordlists/dirb/common.txt
#    - extensions par défaut : php,txt,html
#    - -mc all + -k + filtrage auto -fs (sur fausse URL)
# Sorties : ./mon-recoweb_<target>/{whatweb.txt,whatweb.json,ffuf.csv,summary_ffuf.txt,stats_ffuf.txt}
# Dépendances : whatweb, ffuf, curl, awk, sed
# ------------------------------------------------------------

set -euo pipefail

# Couleurs (coupées si pas TTY)
if [[ -t 1 ]]; then
  C_RST=$'\e[0m'; C_B=$'\e[1m'; C_G=$'\e[32m'; C_Y=$'\e[33m'; C_C=$'\e[36m'; C_R=$'\e[31m'
else
  C_RST=''; C_B=''; C_G=''; C_Y=''; C_C=''; C_R=''
fi

TARGET=""
WORDLIST="/usr/share/wordlists/dirb/common.txt"
EXTS="php,txt,html"
THREADS=40
RATE=""
OUTDIR=""
VERBOSE=false
NOFILTER=false
FORCE_HTTP=false
FORCE_HTTPS=false

usage() {
cat <<EOF
${C_B}Usage:${C_RST} mon-recoweb -t <IP|HOST|URL> [options]

  -t <target>     IP/host ou URL (avec/sans schéma)
  -w <wordlist>   Wordlist (def: ${WORDLIST})
  -x <exts>       Extensions (def: ${EXTS})
  -T <threads>    Threads ffuf (def: ${THREADS})
  -p <rate>       Tempo ffuf, ex: 50ms (facultatif)
  -o <outdir>     Dossier de sortie (def: auto, sans timestamp)
  -v              Verbose
  --http          Forcer HTTP
  --https         Forcer HTTPS
  --no-filter     Désactive le filtrage auto (-fs)

Exemples:
  mon-recoweb -t site.htb
  mon-recoweb -t site.htb -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt
  mon-recoweb -t https://site.htb -x php,txt
EOF
}

log() { echo -e "${C_C}[i]${C_RST} $*"; }
ok()  { echo -e "${C_G}[✓]${C_RST} $*"; }
warn(){ echo -e "${C_Y}[!]${C_RST} $*"; }
err() { echo -e "${C_R}[✗]${C_RST} $*" >&2; }

# Parse args
while [[ $# -gt 0 ]]; do
  case "$1" in
    -t) TARGET="$2"; shift 2 ;;
    -w) WORDLIST="$2"; shift 2 ;;
    -x) EXTS="$2"; shift 2 ;;
    -T) THREADS="$2"; shift 2 ;;
    -p) RATE="$2"; shift 2 ;;
    -o) OUTDIR="$2"; shift 2 ;;
    -v) VERBOSE=true; shift ;;
    --http)  FORCE_HTTP=true; shift ;;
    --https) FORCE_HTTPS=true; shift ;;
    --no-filter) NOFILTER=true; shift ;;
    -h|--help) usage; exit 0 ;;
    *) err "Option inconnue: $1"; usage; exit 1 ;;
  esac
done

[[ -z "${TARGET}" ]] && { err "Cible manquante (-t)."; usage; exit 1; }
[[ ! -f "${WORDLIST}" ]] && { err "Wordlist introuvable: ${WORDLIST}"; exit 1; }
command -v whatweb >/dev/null 2>&1 || { err "whatweb manquant"; exit 1; }
command -v ffuf    >/dev/null 2>&1 || { err "ffuf manquant"; exit 1; }

# ---------- Dossier sortie (sans timestamp) ----------
SAFE_TGT="$(echo "${TARGET}" | sed 's#[/:]#_#g')"
OUTDIR="${OUTDIR:-mon-recoweb_${SAFE_TGT}}"
# Pour repartir propre à chaque run, décommente la ligne suivante :
# rm -rf "${OUTDIR}"
mkdir -p "${OUTDIR}"
ok "Dossier de travail: ${OUTDIR}"

# Détermination schéma
base_host="${TARGET}"
if [[ "${TARGET}" =~ ^https?:// ]]; then
  BASE_URL="${TARGET%/}"
  base_host="$(echo "${TARGET}" | sed -E 's#^https?://##' | cut -d/ -f1)"
else
  if ${FORCE_HTTP}; then
    BASE_URL="http://${TARGET}"
  elif ${FORCE_HTTPS}; then
    BASE_URL="https://${TARGET}"
  else
    if curl -k -sI "https://${TARGET}" >/dev/null 2>&1; then
      BASE_URL="https://${TARGET}"
    else
      BASE_URL="http://${TARGET}"
    fi
  fi
fi
ok "Base URL : ${BASE_URL}"

# 1) WHATWEB (sortie texte propre + JSON)
log "WhatWeb (-a 3)…"
whatweb -a 3 "${BASE_URL}" | sed -r 's/\x1B\[[0-9;]*[A-Za-z]//g' | tee "${OUTDIR}/whatweb.txt"
whatweb -a 3 "${BASE_URL}" --log-json="${OUTDIR}/whatweb.json" >/dev/null 2>&1 || true
[[ ! -s "${OUTDIR}/whatweb.txt" ]] && warn "whatweb.txt est vide"

# 2) FFUF (enum dirs/fichiers) — -mc all, -k, filtrage auto -fs (sauf --no-filter)
RANDPATH="__this_should_not_exist__$(tr -dc 'a-z0-9' </dev/urandom | head -c 10)"
TESTURL="${BASE_URL}/${RANDPATH}"
SIZE_FILTER=""
if ! ${NOFILTER}; then
  SIZE_404="$(curl -k -s -o /dev/null -w '%{size_download}\n' "${TESTURL}" || echo "0")"
  [[ "${SIZE_404}" != "0" ]] && SIZE_FILTER="-fs ${SIZE_404}"
  log "Taille 'bruit' détectée (fs): ${SIZE_404} octets"
else
  warn "Filtrage auto désactivé (--no-filter)"
fi

FFUF_URL="${BASE_URL}/FUZZ"
FFUF_CSV="${OUTDIR}/ffuf.csv"
FFUF_OPTS=( -u "${FFUF_URL}" -w "${WORDLIST}" -mc all -k -t "${THREADS}" -x "${EXTS}" -of csv -o "${FFUF_CSV}" )
[[ -n "${RATE}" ]] && FFUF_OPTS+=( -p "${RATE}" )
[[ -n "${SIZE_FILTER}" ]] && FFUF_OPTS+=( ${SIZE_FILTER} )

log "FFUF : wordlist=${WORDLIST} | exts=${EXTS} | threads=${THREADS} ${RATE:+| rate=${RATE}} ${SIZE_FILTER:+| ${SIZE_FILTER}}"
${VERBOSE} && echo "+ ffuf ${FFUF_OPTS[*]}"
ffuf "${FFUF_OPTS[@]}" | sed -n '1,3p' || true

# Résumés
SUMMARY="${OUTDIR}/summary_ffuf.txt"
STATS="${OUTDIR}/stats_ffuf.txt"
if [[ -s "${FFUF_CSV}" ]]; then
  awk -F',' 'NR==1 {next} {printf "%-4s  len=%-7s  %s\n", $4, $5, $2}' "${FFUF_CSV}" \
    | sed 's|"||g' | sort -u > "${SUMMARY}"
  {
    echo "== Stats par code HTTP =="
    awk -F',' 'NR>1 {cnt[$4]++} END{for (s in cnt) printf "HTTP %s : %d\n", s, cnt[s]}' "${FFUF_CSV}" | sed 's|"||g' | sort
    echo
    echo "== Top 10 tailles les plus fréquentes =="
    awk -F',' 'NR>1 {cnt[$5]++} END{for (l in cnt) printf "len=%s : %d\n", l, cnt[l]}' "${FFUF_CSV}" | sed 's|"||g' | sort -nr -k2 | head
  } > "${STATS}"
  ok "Terminé. Résumé : ${SUMMARY}"
else
  warn "FFUF n’a rien écrit (aucun hit ou ban)."
fi

echo
ok "Recon web (lite) terminé."
echo -e "  → Dossier : ${C_B}${OUTDIR}${C_RST}"
echo "    - whatweb.txt | whatweb.json"
echo "    - ffuf.csv | summary_ffuf.txt | stats_ffuf.txt"
