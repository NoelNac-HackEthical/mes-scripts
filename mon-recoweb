#!/usr/bin/env bash
# mon-recoweb (lite, per-extension files, ffuf always runs)
# -----------------------------------------------------------------------------
# 1) whatweb (CMS/technos)
# 2) ffuf répertoires (sans -fs par défaut)
# 3) ffuf fichiers -> boucle par extension : /FUZZ.<ext>  (robuste vs wordlists polluées)
# Option: --filters pour mesurer et appliquer -fs (dir/file)
# Résultats : ./mon-recoweb_<target>/ + logs + CSV (toujours présents)
# Dépendances : whatweb, ffuf, curl, awk, sed
# -----------------------------------------------------------------------------
# SIG: mon-recoweb vLite-perext-2025-09-05-a

set -euo pipefail
set -o pipefail

# Couleurs (coupées si pas TTY)
if [[ -t 1 ]]; then
  C_RST=$'\e[0m'; C_B=$'\e[1m'; C_G=$'\e[32m'; C_Y=$'\e[33m'; C_C=$'\e[36m'; C_R=$'\e[31m'
else
  C_RST=''; C_B=''; C_G=''; C_Y=''; C_C=''; C_R=''
fi

TARGET=""
WORDLIST="/usr/share/wordlists/dirb/common.txt"
EXTS="php,txt,html"   # -x <exts> alimente cette variable
THREADS=40
RATE=""
OUTDIR=""
VERBOSE=false
USE_FILTERS=false
FORCE_HTTP=false
FORCE_HTTPS=false

usage() {
cat <<EOF
${C_B}Usage:${C_RST} mon-recoweb -t <IP|HOST|URL> [options]

  -t <target>     IP/host ou URL (avec/sans schéma)
  -w <wordlist>   Wordlist (def: ${WORDLIST})
  -x <exts>       Extensions fichiers, ex: php,txt,html (def: ${EXTS})
  -T <threads>    Threads ffuf (def: ${THREADS})
  -p <rate>       Tempo ffuf, ex: 50ms (facultatif)
  -o <outdir>     Dossier de sortie (def: auto, sans timestamp)
  -v              Verbose (trace pas-à-pas)
  --http          Forcer HTTP
  --https         Forcer HTTPS
  --filters       Active les filtres -fs (dir/file) via sondes tolérantes

Exemples:
  mon-recoweb -t planning.htb
  mon-recoweb -t site.htb -x php,html --filters
EOF
}

log()  { echo -e "${C_C}[i]${C_RST} $*"; }
ok()   { echo -e "${C_G}[✓]${C_RST} $*"; }
warn(){ echo -e "${C_Y}[!]${C_RST} $*"; }
err()  { echo -e "${C_R}[✗]${C_RST} $*" >&2; }

# Parse args
while [[ $# -gt 0 ]]; do
  case "$1" in
    -t) TARGET="$2"; shift 2 ;;
    -w) WORDLIST="$2"; shift 2 ;;
    -x) EXTS="$2"; shift 2 ;;
    -T) THREADS="$2"; shift 2 ;;
    -p) RATE="$2"; shift 2 ;;
    -o) OUTDIR="$2"; shift 2 ;;
    -v) VERBOSE=true; shift ;;
    --http)  FORCE_HTTP=true; shift ;;
    --https) FORCE_HTTPS=true; shift ;;
    --filters) USE_FILTERS=true; shift ;;
    -h|--help) usage; exit 0 ;;
    *) err "Option inconnue: $1"; usage; exit 1 ;;
  esac
done

# DEBUG verbeux sûr (compatible set -u)
if $VERBOSE; then
  PS4='+ ${BASH_SOURCE:-'"$0"'}:${LINENO}:${FUNCNAME[0]:-main}: '
  set -x
fi

[[ -z "${TARGET}" ]] && { err "Cible manquante (-t)."; usage; exit 1; }
[[ ! -f "${WORDLIST}" ]] && { err "Wordlist introuvable: ${WORDLIST}"; exit 1; }
command -v whatweb >/dev/null 2>&1 || { err "whatweb manquant"; exit 1; }
command -v ffuf    >/dev/null 2>&1 || { err "ffuf manquant"; exit 1; }

# Dossier sortie (sans timestamp)
SAFE_TGT="$(echo "${TARGET}" | sed 's#[/:]#_#g')"
OUTDIR="${OUTDIR:-mon-recoweb_${SAFE_TGT}}"
mkdir -p "${OUTDIR}"
ok "Dossier de travail: ${OUTDIR}"

# Schéma
base_host="${TARGET}"
if [[ "${TARGET}" =~ ^https?:// ]]; then
  BASE_URL="${TARGET%/}"
  base_host="$(echo "${TARGET}" | sed -E 's#^https?://##' | cut -d/ -f1)"
else
  if ${FORCE_HTTP}; then
    BASE_URL="http://${TARGET}"
  elif ${FORCE_HTTPS}; then
    BASE_URL="https://${TARGET}"
  else
    if curl -k -sI "https://${TARGET}" >/dev/null 2>&1; then
      BASE_URL="https://${TARGET}"
    else
      BASE_URL="http://${TARGET}"
    fi
  fi
fi
ok "Base URL : ${BASE_URL}"

# WhatWeb
log "WhatWeb (-a 3)…"
whatweb -a 3 "${BASE_URL}" | sed -r 's/\x1B\[[0-9;]*[A-Za-z]//g' | tee "${OUTDIR}/whatweb.txt"
whatweb -a 3 "${BASE_URL}" --log-json="${OUTDIR}/whatweb.json" >/dev/null 2>&1 || true
[[ ! -s "${OUTDIR}/whatweb.txt" ]] && warn "whatweb.txt est vide"
echo "[DEBUG] after whatweb ok" >&2

# Filtres -fs (facultatifs, tolérants)
DIR_FILTER=""
FILE_FILTER=""
if ${USE_FILTERS}; then
  set +e
  RANDDIR="__dir__$(tr -dc 'a-z0-9' </dev/urandom | head -c 10)/"
  SIZE_DIR=$(curl -k -sS -o /dev/null -w '%{size_download}\n' "${BASE_URL}/${RANDDIR}"); code_dir=$?
  RANDFILE="__file__$(tr -dc 'a-z0-9' </dev/urandom | head -c 10).php"
  SIZE_FILE=$(curl -k -sS -o /dev/null -w '%{size_download}\n' "${BASE_URL}/${RANDFILE}"); code_file=$?
  set -e
  [[ ${code_dir}  -ne 0 || -z "${SIZE_DIR}"  ]] && SIZE_DIR=0
  [[ ${code_file} -ne 0 || -z "${SIZE_FILE}" ]] && SIZE_FILE=0
  [[ "${SIZE_DIR}"  != "0" ]] && DIR_FILTER="-fs ${SIZE_DIR}"
  [[ "${SIZE_FILE}" != "0" ]] && FILE_FILTER="-fs ${SIZE_FILE}"
  log "Filtres activés: DIR=${DIR_FILTER:-none} FILE=${FILE_FILTER:-none}"
else
  warn "Filtres -fs désactivés (par défaut). Utilise --filters pour les activer."
fi
echo "[DEBUG] after filters ok" >&2

# Helper: exécution ffuf tolérante & logguée, URL classique /FUZZ (pour répertoires)
run_ffuf_dirs () {
  local out_csv="$1" out_log="$2" size_filter="$3"

  local cmd=( ffuf -u "${BASE_URL}/FUZZ" -w "${WORDLIST}" -mc all -k -t "${THREADS}" -of csv -o "${out_csv}" )
  [[ -n "${RATE}" ]]        && cmd+=( -p "${RATE}" )
  [[ -n "${size_filter}" ]] && cmd+=( ${size_filter} )

  echo
  log "=== DÉBUT ffuf (répertoires) ==="
  echo "[CMD] ${cmd[*]}"
  echo "[LOG] ${out_log}"
  echo "[CSV] ${out_csv}"

  set +e
  "${cmd[@]}" >"${out_log}" 2>&1
  local ffuf_status=$?
  set -e

  {
    echo; echo "-----"
    echo "ffuf DIRS terminé avec code: ${ffuf_status}"
    echo "Heure: $(date)"
  } >> "${out_log}"

  if [[ ${ffuf_status} -ge 2 ]]; then
    err "ffuf (dirs) a échoué (code ${ffuf_status}). Regarde ${out_log}"
  elif [[ ${ffuf_status} -eq 1 ]]; then
    warn "ffuf (dirs) aucun résultat (code 1). Voir ${out_log}"
  else
    ok "ffuf (dirs) terminé (code 0)."
  fi

  if [[ ! -f "${out_csv}" ]]; then
    echo "time,url,redirectlocation,status,length,words,lines" > "${out_csv}"
    echo "[i] CSV manquant créé vide: ${out_csv}" >> "${out_log}"
  fi
}

# ---------- 2) FFUF — RÉPERTOIRES ----------
echo "[DEBUG] launching ffuf DIRS" >&2
CSV_DIRS="${OUTDIR}/ffuf_dirs.csv"
LOG_DIRS="${OUTDIR}/ffuf_dirs.log"
SUMMARY_DIRS="${OUTDIR}/summary_dirs.txt"
run_ffuf_dirs "${CSV_DIRS}" "${LOG_DIRS}" "${DIR_FILTER}"

if [[ -s "${CSV_DIRS}" ]]; then
  awk -F',' 'NR==1 {next} {printf "%-4s  len=%-7s  %s\n", $4, $5, $2}' "${CSV_DIRS}" \
    | sed 's|"||g' | sort -u > "${SUMMARY_DIRS}"
else
  : > "${SUMMARY_DIRS}"
fi

# ---------- 3) FFUF — FICHIERS (boucle par extension, URL FUZZ.<ext>) ----------
echo "[DEBUG] launching ffuf FILES (per-ext)" >&2
CSV_FILES="${OUTDIR}/ffuf_files.csv"
LOG_FILES="${OUTDIR}/ffuf_files.log"
SUMMARY_FILES="${OUTDIR}/summary_files.txt"

: > "${CSV_FILES}"
: > "${LOG_FILES}"

IFS=',' read -r -a EXT_ARR <<< "${EXTS}"

# En-tête CSV standard
echo "time,url,redirectlocation,status,length,words,lines" > "${CSV_FILES}"

for raw in "${EXT_ARR[@]}"; do
  ext="${raw// /}"
  [[ -z "$ext" ]] && continue

  PART_CSV="${OUTDIR}/ffuf_files_${ext}.csv"
  PART_LOG="${OUTDIR}/ffuf_files_${ext}.log"

  echo
  log "=== DÉBUT ffuf (files .${ext}) ==="
  echo "[CMD] ffuf -u \"${BASE_URL}/FUZZ.${ext}\" -w \"${WORDLIST}\" -mc all -k -t \"${THREADS}\" -of csv -o \"${PART_CSV}\" ${RATE:+-p ${RATE}} ${FILE_FILTER}"
  echo "[LOG] ${PART_LOG}"
  echo "[CSV] ${PART_CSV}"

  set +e
  ffuf -u "${BASE_URL}/FUZZ.${ext}" \
       -w "${WORDLIST}" \
       -mc all -k -t "${THREADS}" \
       -of csv -o "${PART_CSV}" \
       ${RATE:+-p "${RATE}"} ${FILE_FILTER} >"${PART_LOG}" 2>&1
  ffuf_status=$?
  set -e

  {
    echo; echo "-----"
    echo "ffuf .${ext} terminé avec code: ${ffuf_status}"
    echo "Heure: $(date)"
  } >> "${PART_LOG}"

  # Concat logs
  cat "${PART_LOG}" >> "${LOG_FILES}"

  # Concat CSV (en sautant l'en-tête du PART)
  if [[ -f "${PART_CSV}" && -s "${PART_CSV}" ]]; then
    awk 'NR>1' "${PART_CSV}" >> "${CSV_FILES}"
  fi
done

# Résumé fichiers
if [[ -s "${CSV_FILES}" ]]; then
  awk -F',' 'NR==1 {next} {printf "%-4s  len=%-7s  %s\n", $4, $5, $2}' "${CSV_FILES}" \
    | sed 's|"||g' | sort -u > "${SUMMARY_FILES}"
else
  : > "${SUMMARY_FILES}"
fi

# ---------- Affichage clair ----------
echo
echo -e "${C_B}=== RÉPERTOIRES TROUVÉS ===${C_RST}"
[[ -s "${SUMMARY_DIRS}" ]] && { grep -E '^(301|302|401|403|200|500)' "${SUMMARY_DIRS}" || true; grep -Ev '^(301|302|401|403|200|500)' "${SUMMARY_DIRS}" || true; } || echo "(aucun résultat)"

echo
echo -e "${C_B}=== FICHIERS TROUVÉS (ext: ${EXTS}) ===${C_RST}"
[[ -s "${SUMMARY_FILES}" ]] && { grep -E '^(301|302|401|403|200|500)' "${SUMMARY_FILES}" || true; grep -Ev '^(301|302|401|403|200|500)' "${SUMMARY_FILES}" || true; } || echo "(aucun résultat)"

echo
ok "Recon web (lite) terminé."
echo -e "  → Dossier : ${C_B}${OUTDIR}${C_RST}"
echo "    - whatweb.txt | whatweb.json"
echo "    - ffuf_dirs.csv | ffuf_dirs.log | summary_dirs.txt"
echo "    - ffuf_files.csv | ffuf_files.log | summary_files.txt"
